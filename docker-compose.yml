services:
  # Ollama Service
  ollama:
    image: ollama/ollama:latest
    restart: unless-stopped
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    networks:
      - app-network
    extra_hosts:
      - "registry.ollama.ai:104.16.55.3"  # 加這行，直接用 IP
      - "registry.ollama.ai:104.16.54.3"  # Cloudflare 的備用 IP
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  # PostgreSQL Database with pgvector extension
  postgres:
    image: pgvector/pgvector:pg15  # 使用包含 pgvector 的官方映像
    restart: unless-stopped
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
      - POSTGRES_DB=postgres
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    networks:
      - app-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5

  # pgAdmin - PostgreSQL 圖形化管理工具
  pgadmin:
    image: dpage/pgadmin4:latest
    restart: unless-stopped
    environment:
      - PGADMIN_DEFAULT_EMAIL=admin@admin.com
      - PGADMIN_DEFAULT_PASSWORD=admin
      - PGADMIN_CONFIG_SERVER_MODE=False
      - PGADMIN_CONFIG_MASTER_PASSWORD_REQUIRED=False
    volumes:
      - pgadmin_data:/var/lib/pgadmin
    ports:
      - "5050:80"
    networks:
      - app-network
    depends_on:
      postgres:
        condition: service_healthy

  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
      network: host
    restart: unless-stopped
    environment:
      - PROJECT_ROOT=${PROJECT_ROOT}
      - HOST=${HOST}
      - PORT=8080
      - RELOAD=${RELOAD}
      - WORKERS=${WORKERS}
      - LOG_LEVEL=${LOG_LEVEL}
      - ADMIN_TOKEN=${ADMIN_TOKEN}
      - SESSION_TTL_SEC=${SESSION_TTL_SEC}
      - AUTO_RAG_INDEX=true
      - RAG_DIR=./rag_store
      - RAG_STORE_DIR=./rag_store
      - OLLAMA_EMBED_MODEL=bge-m3
      - OLLAMA_BASE=http://ollama:11434
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      - MY_API_KEY=${MY_API_KEY}
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
      - POSTGRES_DB=postgres
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
    volumes:
      - ./backend/src:/app/src:delegated
      - ./backend/segment:/app/segment
      - ./backend/rag_store:/app/rag_store
      - ./backend/prompts:/app/prompts
      - ../video:/app/video:ro
      - ~/.cache/huggingface:/root/.cache/huggingface:ro  # 掛載 Hugging Face 模型緩存
    dns:
      - 8.8.8.8
      - 8.8.4.4
    # ports:
    #   - "8080:8080"  # 移除對外暴露，改由 nginx 反向代理
    networks:
      - app-network
    depends_on:
      postgres:
        condition: service_healthy
      ollama:
        condition: service_started

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
      network: host
    restart: unless-stopped
    environment:
      # 不設置 REACT_APP_API_BASE，讓前端根據 hostname 自動選擇
      # - REACT_APP_API_BASE=http://localhost:8080  # 已移除，改為自動檢測
      - WDS_SOCKET_HOST=localhost
      - WDS_SOCKET_PORT=3000
    volumes:
      - ./frontend:/app:delegated
      - node_modules_data:/app/node_modules
    dns:
      - 8.8.8.8
      - 8.8.4.4
    # ports:
    #   - "3000:3000"  # 移除對外暴露，改由 nginx 反向代理
    networks:
      - app-network
    depends_on:
      - backend

  # Nginx Reverse Proxy - 統一入口
  nginx:
    image: nginx:alpine
    restart: unless-stopped
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
    ports:
      - "3000:80"      # 廠商開放 3000，所以 Nginx 監聽 3000（映射到容器內部的 80）
      # - "8080:80"    # 備用：如果廠商也開放 8080，可以同時監聽兩個端口
    networks:
      - app-network
    depends_on:
      - backend
      - frontend

networks:
  app-network:
    driver: bridge

volumes:
  node_modules_data:
  ollama_data:
  postgres_data:
  pgadmin_data:

